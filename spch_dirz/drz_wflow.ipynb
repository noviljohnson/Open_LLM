{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\novil\\anaconda3\\envs\\dafl_budget\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pyannote.audio import Pipeline\n",
    "from whisper import load_model\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "# config.read(r'N:\\Open_LLM\\spch_dirz\\hf_conf.config')\n",
    "config.read(r'N:\\DataFlo\\df_config.config')\n",
    "\n",
    "hf_keys = config['HF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Videos\n",
    "def download_videos(base_url):\n",
    "    \"\"\"\n",
    "    Downloads all videos from the given base URL.\n",
    "    \"\"\"\n",
    "    print(\"Downloading videos...\")\n",
    "    output_dir = \"videos\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Use yt-dlp to download videos\n",
    "    subprocess.run([\"yt-dlp\", \"-o\", f\"{output_dir}/%(title)s.%(ext)s\", base_url])\n",
    "    print(\"Videos downloaded successfully.\")\n",
    "    return output_dir\n",
    "\n",
    "# Step 2: Extract Audio from Videos\n",
    "def extract_audio(video_dir):\n",
    "    \"\"\"\n",
    "    Extracts audio from all videos in the given directory.\n",
    "    \"\"\"\n",
    "    print(\"Extracting audio...\")\n",
    "    audio_dir = r\"N:\\Open_LLM\\spch_dirz\\audio\"\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "    for video_file in os.listdir(video_dir):\n",
    "        if video_file.endswith((\".mp4\", \".mkv\", \".webm\")):\n",
    "            video_path = os.path.join(video_dir, video_file)\n",
    "            audio_path = os.path.join(audio_dir, os.path.splitext(video_file)[0] + \".wav\")\n",
    "            print(video_path)\n",
    "            print(audio_path)\n",
    "            subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-q:a\", \"0\", \"-map\", \"a\", audio_path])\n",
    "    print(\"Audio extraction completed.\")\n",
    "    return audio_dir\n",
    "\n",
    "\n",
    "# Step 3: Generate Transcript for Each Audio File\n",
    "def generate_transcripts(audio_dir):\n",
    "    \"\"\"\n",
    "    Generates transcripts for all audio files using Whisper.\n",
    "    \"\"\"\n",
    "    print(\"Generating transcripts...\")\n",
    "    transcript_dir = \"transcripts\"\n",
    "    os.makedirs(transcript_dir, exist_ok=True)\n",
    "\n",
    "    model = load_model(\"base\")  # Load Whisper model\n",
    "    transcripts = {}\n",
    "\n",
    "    for audio_file in os.listdir(audio_dir):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audio_dir, audio_file)\n",
    "            result = model.transcribe(audio_path)\n",
    "            transcript_path = os.path.join(transcript_dir, os.path.splitext(audio_file)[0] + \".json\")\n",
    "            with open(transcript_path, \"w\") as f:\n",
    "                json.dump(result, f)\n",
    "            transcripts[audio_file] = result\n",
    "    print(\"Transcripts generated successfully.\")\n",
    "    return transcripts\n",
    "\n",
    "\n",
    "# Step 4: Perform Speech Diarization\n",
    "def perform_diarization(audio_dir):\n",
    "    \"\"\"\n",
    "    Performs speech diarization to identify speakers and their timestamps.\n",
    "    \"\"\"\n",
    "    print(\"Performing speech diarization...\")\n",
    "    diarization_dir = \"diarization\"\n",
    "    os.makedirs(diarization_dir, exist_ok=True)\n",
    "\n",
    "    # pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=hf_keys['hf_key'])\n",
    "    pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=hf_keys['hf_key'])\n",
    "    diarizations = {}\n",
    "\n",
    "    for audio_file in os.listdir(audio_dir):\n",
    "        if audio_file.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(audio_dir, audio_file)\n",
    "            diarization = pipeline(audio_path, min_speakers=2, max_speakers=15)\n",
    "            diarization_data = []\n",
    "\n",
    "            for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                diarization_data.append({\n",
    "                    \"start\": turn.start,\n",
    "                    \"end\": turn.end,\n",
    "                    \"speaker\": speaker\n",
    "                })\n",
    "\n",
    "            diarizations[audio_file] = diarization_data\n",
    "\n",
    "            # Save diarization data to a JSON file\n",
    "            diarization_path = os.path.join(diarization_dir, os.path.splitext(audio_file)[0] + \".json\")\n",
    "            with open(diarization_path, \"w\") as f:\n",
    "                json.dump(diarization_data, f, indent=4)\n",
    "\n",
    "    print(\"Speech diarization completed.\")\n",
    "    return diarizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 5: Combine Timestamps, Speaker Names, and Transcripts\n",
    "def combine_results(transcripts, diarizations):\n",
    "    \"\"\"\n",
    "    Combines timestamps, speaker names, and transcripts into a single data structure.\n",
    "    \"\"\"\n",
    "    print(\"Combining results...\")\n",
    "    combined_results = {}\n",
    "\n",
    "    transcript_whole = []\n",
    "    for segment in transcript_segments:\n",
    "        start_time = segment[\"start\"]\n",
    "        end_time = segment[\"end\"]\n",
    "        text = segment[\"text\"]\n",
    "        transcript_whole.append((start_time, end_time, text))\n",
    "\n",
    "    diarization_timestamps = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        diarization_timestamps.append((speaker, turn.start, turn.end))\n",
    "\n",
    "\n",
    "    for audio_file, transcript in transcripts.items():\n",
    "        diarization_data = diarizations.get(audio_file, [])\n",
    "        combined_data = []\n",
    "\n",
    "        for segment in diarization_data:\n",
    "            start_time = segment[\"start\"]\n",
    "            end_time = segment[\"end\"]\n",
    "            speaker = segment[\"speaker\"]\n",
    "\n",
    "            # Extract corresponding transcript segment (basic approximation)\n",
    "            combined_data.append({\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"speaker\": speaker,\n",
    "                \"transcript\": transcript  # Placeholder; refine this for better alignment\n",
    "            })\n",
    "\n",
    "        combined_results[audio_file] = combined_data\n",
    "\n",
    "    # Save combined results to a JSON file\n",
    "    with open(\"combined_results.json\", \"w\") as f:\n",
    "        json.dump(combined_results, f, indent=4)\n",
    "\n",
    "    print(\"Results combined and saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def combine_transcript_and_diarization(transcript, diarization):\n",
    "    \"\"\"\n",
    "    Combine transcript and diarization results into a unified structure.\n",
    "    \n",
    "    Args:\n",
    "        transcript (list): List of transcript segments in the format [(start, end, text), ...].\n",
    "        diarization (list): List of diarization segments in the format [(speaker, start, end), ...].\n",
    "    \n",
    "    Returns:\n",
    "        list: Combined results in the format [(speaker, start, end, text), ...].\n",
    "    \"\"\"\n",
    "    combined_results = []\n",
    "\n",
    "    for t_start, t_end, t_text in transcript:\n",
    "        best_match = None\n",
    "        max_overlap = 0\n",
    "\n",
    "        for speaker, d_start, d_end in diarization:\n",
    "            # Calculate overlap between transcript segment and diarization segment\n",
    "            overlap_start = max(t_start, d_start)\n",
    "            overlap_end = min(t_end, d_end)\n",
    "            overlap = max(0, overlap_end - overlap_start)\n",
    "\n",
    "            # Find the best match based on maximum overlap\n",
    "            if overlap > max_overlap:\n",
    "                max_overlap = overlap\n",
    "                best_match = (speaker, d_start, d_end)\n",
    "\n",
    "        if best_match:\n",
    "            speaker, d_start, d_end = best_match\n",
    "            combined_results.append((speaker, t_start, t_end, t_text))\n",
    "\n",
    "    # Combine consecutive lines for the same speaker    \n",
    "    merged_results = []\n",
    "    current_speaker = None\n",
    "    current_start = None\n",
    "    current_end = None\n",
    "    current_text = []\n",
    "\n",
    "    for speaker, start, end, text in combined_results:\n",
    "        if speaker == current_speaker:\n",
    "            # Same speaker, extend the current segment\n",
    "            current_end = end\n",
    "            current_text.append(text)\n",
    "        else:\n",
    "            # New speaker, save the previous segment\n",
    "            if current_speaker is not None:\n",
    "                merged_results.append((current_speaker, current_start, current_end, \" \".join(current_text)))\n",
    "            # Start a new segment\n",
    "            current_speaker = speaker\n",
    "            current_start = start\n",
    "            current_end = end\n",
    "            current_text = [text]\n",
    "\n",
    "    # Add the last segment\n",
    "    if current_speaker is not None:\n",
    "        merged_results.append((current_speaker, current_start, current_end, \" \".join(current_text)))\n",
    "\n",
    "    \n",
    "    with open(\"combined_results.json\", \"w\") as f:\n",
    "        json.dump(merged_results, f, indent=4)\n",
    "\n",
    "    return merged_results\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def list_vdos():\n",
    "        \n",
    "    # URL of the webpage\n",
    "    url = \"https://sg001-harmony.sliq.net/00293/Harmony/en/View/RecentEnded/20250224/-1\"\n",
    "\n",
    "    # Fetch the webpage\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Extract video links\n",
    "    video_links = []\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        if \"/PowerBrowser/PowerBrowserV2/\" in href:\n",
    "            full_url = f\"https://sg001-harmony.sliq.net{href}\"\n",
    "            video_links.append(full_url)\n",
    "\n",
    "    all_m3u8_links = []\n",
    "    for url2 in video_links:\n",
    "        # Fetch the webpage\n",
    "        response = requests.get(url2)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "        # Search for .m3u8 links\n",
    "        m3u8_links = []\n",
    "        for tag in soup.find_all(\"script\"):\n",
    "            if \".m3u8\" in tag.text:\n",
    "                m3u8_links.append(tag.text.split(\".m3u8\")[0] + \".m3u8\")\n",
    "\n",
    "        all_m3u8_links.append(m3u8_links)\n",
    "    \n",
    "    full_downloadable_urls = []\n",
    "    for vdo in all_m3u8_links:\n",
    "        full_downloadable_urls.append(\"https\"+vdo[0].split('https')[-1])\n",
    "    \n",
    "    return full_downloadable_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo_list = list_vdos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Consumer%20and%20Public%20Affairs_2025-03-04-16.30.13_76811_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Appropriations%20and%20Finance_2025-03-04-17.01.11_76814_14.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-live/house/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Labor%2C%20Veterans%20and%20Military%20Affairs_2025-03-04-17.00.50_76813_34.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Test%20Meeting_2025-03-04-16.08.54_76810_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Senate%20Chamber_2025-03-04-11.51.13_76808_10.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Test%20Meeting_2025-03-04-16.07.20_76809_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Chamber%20Meeting_2025-03-04-10.44.58_76807_6.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Senate%20-%20Finance_2025-03-04-09.04.08_76804_50.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Senate%20-%20Conservation_2025-03-04-09.05.38_76806_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Energy%2C%20Environment%20and%20Natural%20Resources_2025-03-04-08.32.20_76800_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Agriculture%2C%20Acequias%20And%20Water%20Resources_2025-03-04-09.03.24_76803_34.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Transportation%20and%20Public%20Works_2025-03-04-09.00.05_76802_26.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/House%20-%20Rural%20Development%2C%20Land%20Grants%20And%20Cultural%20Affairs_2025-03-04-09.04.19_76805_22.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Test%20Meeting_2025-03-04-08.45.32_76801_6.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-live/house/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Test%20Meeting_2025-03-04-08.19.01_76797_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Test%20Meeting_2025-03-04-08.19.32_76798_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-live/house/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20-%20Judiciary_2025-03-03-18.41.25_76795_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20-%20Health%20and%20Public%20Affairs_2025-03-03-17.37.16_76793_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20-%20Judiciary_2025-03-03-17.43.37_76794_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Commerce%20and%20Economic%20Development_2025-03-03-14.33.52_76788_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Appropriations%20and%20Finance_2025-03-03-14.32.15_76787_14.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20Chamber_2025-03-03-11.39.45_76786_10.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Judiciary_2025-03-03-14.37.10_76789_26.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Chamber%20Meeting_2025-03-03-11.05.08_76785_6.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20-%20Education_2025-03-03-09.05.35_76782_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20-%20Finance_2025-03-03-09.06.18_76783_50.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Government%2C%20Elections%20And%20Indian%20Affairs_2025-03-03-08.43.25_76781_22.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Taxation%20and%20Revenue_2025-03-03-08.38.52_76780_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Health%20and%20Human%20Services_2025-03-03-08.04.43_76773_14.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/Senate%20-%20Rules_2025-03-03-08.36.00_76779_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/03/House%20-%20Education_2025-03-03-08.32.09_76778_26.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/02/Senate%20-%20Health%20and%20Public%20Affairs_2025-03-02-13.06.01_76772_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/House%20-%20Chamber%20Meeting_2025-03-01-13.00.09_76767_6.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/Senate%20-%20Tax%2C%20Business%20and%20Transportation_2025-03-01-19.01.24_76770_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/Senate%20-%20Tax%2C%20Business%20and%20Transportation_2025-03-01-18.52.22_76769_30.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/Senate%20Chamber_2025-03-01-13.08.24_76768_10.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/Senate%20-%20Finance_2025-03-01-11.11.40_76764_50.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/House%20-%20Government%2C%20Elections%20And%20Indian%20Affairs_2025-03-01-10.02.10_76761_22.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/House%20-%20Energy%2C%20Environment%20and%20Natural%20Resources_2025-03-01-08.22.17_76758_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/Senate%20-%20Judiciary_2025-03-01-10.10.40_76762_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/House%20-%20Judiciary_2025-03-01-08.42.45_76759_26.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/01/House%20-%20Chamber%20Meeting_2025-03-01-11.32.33_76765_6.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/02/28/House%20-%20Judiciary_2025-02-28-15.45.23_76755_26.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/02/28/Senate%20-%20Judiciary_2025-02-28-15.10.39_76751_46.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/02/28/House%20-%20Commerce%20and%20Economic%20Development_2025-02-28-15.39.59_76754_38.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/02/28/House%20-%20Appropriations%20and%20Finance_2025-02-28-15.39.50_76753_14.mp4/playlist.m3u8',\n",
       " 'https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/02/28/Senate%20-%20Health%20and%20Public%20Affairs_2025-02-28-15.11.35_76752_30.mp4/playlist.m3u8']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading videos...\n",
      "Videos downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "res = download_videos(\"https://sg002-live.sliq.net/00293-vod-2/_definst_/2025/03/04/Test%20Meeting_2025-03-04-16.08.54_76810_46.mp4/playlist.m3u8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio...\n",
      "N:\\Open_LLM\\spch_dirz\\videos\\playlist.mp4\n",
      "N:\\Open_LLM\\spch_dirz\\audio\\playlist.wav\n",
      "Audio extraction completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'N:\\\\Open_LLM\\\\spch_dirz\\\\audio'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_audio(r\"N:\\Open_LLM\\spch_dirz\\videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transcripts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\novil\\anaconda3\\envs\\dafl_budget\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts generated successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'playlist.wav': {'text': ' I will try and put these, to keep going I think this will stand. System Sinne Testing iPhone testing mic you Good evening great and in part of your course! week The you this period is My Test. The testing-my.',\n",
       "  'segments': [{'id': 0,\n",
       "    'seek': 0,\n",
       "    'start': 0.0,\n",
       "    'end': 2.8000000000000003,\n",
       "    'text': ' I will try and put these,',\n",
       "    'tokens': [50364, 286, 486, 853, 293, 829, 613, 11, 50504],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 1,\n",
       "    'seek': 0,\n",
       "    'start': 2.8000000000000003,\n",
       "    'end': 7.96,\n",
       "    'text': ' to keep going I think this will stand.',\n",
       "    'tokens': [50504, 281, 1066, 516, 286, 519, 341, 486, 1463, 13, 50762],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 2,\n",
       "    'seek': 0,\n",
       "    'start': 9.8,\n",
       "    'end': 12.540000000000001,\n",
       "    'text': ' System',\n",
       "    'tokens': [50854, 8910, 50991],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 3,\n",
       "    'seek': 0,\n",
       "    'start': 12.540000000000001,\n",
       "    'end': 15.52,\n",
       "    'text': ' Sinne',\n",
       "    'tokens': [50991, 47041, 51140],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 4,\n",
       "    'seek': 0,\n",
       "    'start': 17.84,\n",
       "    'end': 20.580000000000002,\n",
       "    'text': ' Testing',\n",
       "    'tokens': [51256, 45517, 51393],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 5,\n",
       "    'seek': 0,\n",
       "    'start': 20.580000000000002,\n",
       "    'end': 21.78,\n",
       "    'text': ' iPhone',\n",
       "    'tokens': [51393, 7252, 51453],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 6,\n",
       "    'seek': 0,\n",
       "    'start': 24.78,\n",
       "    'end': 28.28,\n",
       "    'text': ' testing mic',\n",
       "    'tokens': [51603, 4997, 3123, 51778],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.440010472347862,\n",
       "    'compression_ratio': 1.1555555555555554,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 7,\n",
       "    'seek': 2828,\n",
       "    'start': 28.28,\n",
       "    'end': 30.28,\n",
       "    'text': ' you',\n",
       "    'tokens': [50364, 291, 50464],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.7951796650886536,\n",
       "    'compression_ratio': 0.2727272727272727,\n",
       "    'no_speech_prob': 0.9397321939468384},\n",
       "   {'id': 8,\n",
       "    'seek': 5828,\n",
       "    'start': 58.32,\n",
       "    'end': 61.92,\n",
       "    'text': ' Good evening',\n",
       "    'tokens': [50366, 2205, 5634, 50546],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 9,\n",
       "    'seek': 5828,\n",
       "    'start': 61.92,\n",
       "    'end': 70.5,\n",
       "    'text': ' great',\n",
       "    'tokens': [50546, 869, 50975],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 10,\n",
       "    'seek': 5828,\n",
       "    'start': 74.0,\n",
       "    'end': 75.0,\n",
       "    'text': ' and',\n",
       "    'tokens': [51150, 293, 51200],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 11,\n",
       "    'seek': 5828,\n",
       "    'start': 75.0,\n",
       "    'end': 78.34,\n",
       "    'text': ' in',\n",
       "    'tokens': [51200, 294, 51367],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 12,\n",
       "    'seek': 5828,\n",
       "    'start': 79.7,\n",
       "    'end': 81.36,\n",
       "    'text': ' part of your',\n",
       "    'tokens': [51435, 644, 295, 428, 51518],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 13,\n",
       "    'seek': 5828,\n",
       "    'start': 81.36,\n",
       "    'end': 84.04,\n",
       "    'text': ' course!',\n",
       "    'tokens': [51518, 1164, 0, 51652],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 14,\n",
       "    'seek': 5828,\n",
       "    'start': 85.04,\n",
       "    'end': 88.1,\n",
       "    'text': ' week',\n",
       "    'tokens': [51702, 1243, 51855],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.667894151475695,\n",
       "    'compression_ratio': 0.8947368421052632,\n",
       "    'no_speech_prob': 0.1311090737581253},\n",
       "   {'id': 15,\n",
       "    'seek': 8810,\n",
       "    'start': 88.1,\n",
       "    'end': 114.3,\n",
       "    'text': ' The',\n",
       "    'tokens': [50364, 440, 51674],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -2.1926483154296874,\n",
       "    'compression_ratio': 0.2727272727272727,\n",
       "    'no_speech_prob': 0.3397998511791229},\n",
       "   {'id': 16,\n",
       "    'seek': 11430,\n",
       "    'start': 114.3,\n",
       "    'end': 116.3,\n",
       "    'text': ' you',\n",
       "    'tokens': [50364, 291, 50464],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.7987757325172424,\n",
       "    'compression_ratio': 0.2727272727272727,\n",
       "    'no_speech_prob': 0.9527100324630737},\n",
       "   {'id': 17,\n",
       "    'seek': 14430,\n",
       "    'start': 144.3,\n",
       "    'end': 171.96,\n",
       "    'text': ' this period is',\n",
       "    'tokens': [50390, 341, 2896, 307, 51747],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.5918833414713545,\n",
       "    'compression_ratio': 0.6363636363636364,\n",
       "    'no_speech_prob': 0.1361747682094574},\n",
       "   {'id': 18,\n",
       "    'seek': 17430,\n",
       "    'start': 174.3,\n",
       "    'end': 181.28,\n",
       "    'text': ' My Test.',\n",
       "    'tokens': [50364, 1222, 9279, 13, 50713],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -1.801983424595424,\n",
       "    'compression_ratio': 0.5,\n",
       "    'no_speech_prob': 0.31533491611480713},\n",
       "   {'id': 19,\n",
       "    'seek': 18128,\n",
       "    'start': 181.28,\n",
       "    'end': 203.68,\n",
       "    'text': ' The',\n",
       "    'tokens': [50364, 440, 51484],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -2.3598501205444338,\n",
       "    'compression_ratio': 0.2727272727272727,\n",
       "    'no_speech_prob': 0.3655783236026764},\n",
       "   {'id': 20,\n",
       "    'seek': 20368,\n",
       "    'start': 203.68,\n",
       "    'end': 228.82,\n",
       "    'text': ' testing-my.',\n",
       "    'tokens': [50364, 4997, 12, 2226, 13, 51621],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -2.669729777744838,\n",
       "    'compression_ratio': 0.5789473684210527,\n",
       "    'no_speech_prob': 0.24228648841381073}],\n",
       "  'language': 'en'},\n",
       " 'test_meeting.wav': {'text': \" I'm curious. you testing mind What Jason. testing my I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. My test. The test. Testing my. To My test.\",\n",
       "  'segments': [{'id': 0,\n",
       "    'seek': 0,\n",
       "    'start': 0.0,\n",
       "    'end': 17.36,\n",
       "    'text': \" I'm curious.\",\n",
       "    'tokens': [50364, 286, 478, 6369, 13, 51232],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -2.8636183057512556,\n",
       "    'compression_ratio': 0.6,\n",
       "    'no_speech_prob': 0.18331240117549896},\n",
       "   {'id': 1,\n",
       "    'seek': 3000,\n",
       "    'start': 30.0,\n",
       "    'end': 32.0,\n",
       "    'text': ' you',\n",
       "    'tokens': [50364, 291, 50464],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.7851393818855286,\n",
       "    'compression_ratio': 0.2727272727272727,\n",
       "    'no_speech_prob': 0.9421381950378418},\n",
       "   {'id': 2,\n",
       "    'seek': 6000,\n",
       "    'start': 60.06,\n",
       "    'end': 63.74,\n",
       "    'text': ' testing mind',\n",
       "    'tokens': [50367, 4997, 1575, 50551],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.877640247344971,\n",
       "    'compression_ratio': 0.68,\n",
       "    'no_speech_prob': 0.18976294994354248},\n",
       "   {'id': 3,\n",
       "    'seek': 6000,\n",
       "    'start': 66.7,\n",
       "    'end': 67.16,\n",
       "    'text': ' What',\n",
       "    'tokens': [50699, 708, 50722],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -4.877640247344971,\n",
       "    'compression_ratio': 0.68,\n",
       "    'no_speech_prob': 0.18976294994354248},\n",
       "   {'id': 4,\n",
       "    'seek': 9000,\n",
       "    'start': 90.0,\n",
       "    'end': 110.42,\n",
       "    'text': ' Jason.',\n",
       "    'tokens': [50364, 11181, 13, 51385],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -3.0066397984822593,\n",
       "    'compression_ratio': 0.42857142857142855,\n",
       "    'no_speech_prob': 0.2858550548553467},\n",
       "   {'id': 5,\n",
       "    'seek': 11042,\n",
       "    'start': 110.42,\n",
       "    'end': 119.18,\n",
       "    'text': ' testing my',\n",
       "    'tokens': [50364, 4997, 452, 50802],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -2.1865148544311523,\n",
       "    'compression_ratio': 0.5555555555555556,\n",
       "    'no_speech_prob': 0.26927119493484497},\n",
       "   {'id': 6,\n",
       "    'seek': 14042,\n",
       "    'start': 140.42,\n",
       "    'end': 144.42,\n",
       "    'text': \" I'm going to start with the\",\n",
       "    'tokens': [50364, 286, 478, 516, 281, 722, 365, 264, 50564],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9124573794278231,\n",
       "    'compression_ratio': 2.32,\n",
       "    'no_speech_prob': 0.16709646582603455},\n",
       "   {'id': 7,\n",
       "    'seek': 14042,\n",
       "    'start': 144.42,\n",
       "    'end': 148.42,\n",
       "    'text': ' first one.',\n",
       "    'tokens': [50564, 700, 472, 13, 50764],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9124573794278231,\n",
       "    'compression_ratio': 2.32,\n",
       "    'no_speech_prob': 0.16709646582603455},\n",
       "   {'id': 8,\n",
       "    'seek': 14042,\n",
       "    'start': 148.42,\n",
       "    'end': 152.42,\n",
       "    'text': \" I'm going to start with the\",\n",
       "    'tokens': [50764, 286, 478, 516, 281, 722, 365, 264, 50964],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9124573794278231,\n",
       "    'compression_ratio': 2.32,\n",
       "    'no_speech_prob': 0.16709646582603455},\n",
       "   {'id': 9,\n",
       "    'seek': 14042,\n",
       "    'start': 152.42,\n",
       "    'end': 156.42,\n",
       "    'text': ' first one.',\n",
       "    'tokens': [50964, 700, 472, 13, 51164],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9124573794278231,\n",
       "    'compression_ratio': 2.32,\n",
       "    'no_speech_prob': 0.16709646582603455},\n",
       "   {'id': 10,\n",
       "    'seek': 14042,\n",
       "    'start': 156.42,\n",
       "    'end': 160.42,\n",
       "    'text': \" I'm going to start with the\",\n",
       "    'tokens': [51164, 286, 478, 516, 281, 722, 365, 264, 51364],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9124573794278231,\n",
       "    'compression_ratio': 2.32,\n",
       "    'no_speech_prob': 0.16709646582603455},\n",
       "   {'id': 11,\n",
       "    'seek': 14042,\n",
       "    'start': 160.42,\n",
       "    'end': 164.42,\n",
       "    'text': ' first one.',\n",
       "    'tokens': [51364, 700, 472, 13, 51564],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9124573794278231,\n",
       "    'compression_ratio': 2.32,\n",
       "    'no_speech_prob': 0.16709646582603455},\n",
       "   {'id': 12,\n",
       "    'seek': 16442,\n",
       "    'start': 164.42,\n",
       "    'end': 166.42,\n",
       "    'text': \" I'm going to start with the\",\n",
       "    'tokens': [50364, 286, 478, 516, 281, 722, 365, 264, 50464],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.284221567426409,\n",
       "    'compression_ratio': 1.4827586206896552,\n",
       "    'no_speech_prob': 0.33155882358551025},\n",
       "   {'id': 13,\n",
       "    'seek': 16442,\n",
       "    'start': 166.42,\n",
       "    'end': 170.42,\n",
       "    'text': ' first one.',\n",
       "    'tokens': [50464, 700, 472, 13, 50664],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.284221567426409,\n",
       "    'compression_ratio': 1.4827586206896552,\n",
       "    'no_speech_prob': 0.33155882358551025},\n",
       "   {'id': 14,\n",
       "    'seek': 16442,\n",
       "    'start': 170.42,\n",
       "    'end': 172.42,\n",
       "    'text': \" I'm going to start with the\",\n",
       "    'tokens': [50664, 286, 478, 516, 281, 722, 365, 264, 50764],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.284221567426409,\n",
       "    'compression_ratio': 1.4827586206896552,\n",
       "    'no_speech_prob': 0.33155882358551025},\n",
       "   {'id': 15,\n",
       "    'seek': 16442,\n",
       "    'start': 172.42,\n",
       "    'end': 176.42,\n",
       "    'text': ' first one.',\n",
       "    'tokens': [50764, 700, 472, 13, 50964],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.284221567426409,\n",
       "    'compression_ratio': 1.4827586206896552,\n",
       "    'no_speech_prob': 0.33155882358551025},\n",
       "   {'id': 16,\n",
       "    'seek': 16442,\n",
       "    'start': 176.42,\n",
       "    'end': 182.42,\n",
       "    'text': ' My test.',\n",
       "    'tokens': [50964, 1222, 1500, 13, 51264],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.284221567426409,\n",
       "    'compression_ratio': 1.4827586206896552,\n",
       "    'no_speech_prob': 0.33155882358551025},\n",
       "   {'id': 17,\n",
       "    'seek': 18242,\n",
       "    'start': 182.42,\n",
       "    'end': 206.42,\n",
       "    'text': ' The test.',\n",
       "    'tokens': [50364, 440, 1500, 13, 51564],\n",
       "    'temperature': 0.6,\n",
       "    'avg_logprob': -0.8211670716603597,\n",
       "    'compression_ratio': 0.7777777777777778,\n",
       "    'no_speech_prob': 0.24375367164611816},\n",
       "   {'id': 18,\n",
       "    'seek': 18242,\n",
       "    'start': 206.42,\n",
       "    'end': 210.42,\n",
       "    'text': ' Testing my.',\n",
       "    'tokens': [51564, 45517, 452, 13, 51764],\n",
       "    'temperature': 0.6,\n",
       "    'avg_logprob': -0.8211670716603597,\n",
       "    'compression_ratio': 0.7777777777777778,\n",
       "    'no_speech_prob': 0.24375367164611816},\n",
       "   {'id': 19,\n",
       "    'seek': 21042,\n",
       "    'start': 210.42,\n",
       "    'end': 223.42,\n",
       "    'text': ' To',\n",
       "    'tokens': [50364, 1407, 51014],\n",
       "    'temperature': 1.0,\n",
       "    'avg_logprob': -2.5791736602783204,\n",
       "    'compression_ratio': 0.2,\n",
       "    'no_speech_prob': 0.41759783029556274},\n",
       "   {'id': 20,\n",
       "    'seek': 22342,\n",
       "    'start': 223.42,\n",
       "    'end': 225.42,\n",
       "    'text': ' My test.',\n",
       "    'tokens': [50364, 1222, 1500, 13, 50464],\n",
       "    'temperature': 0.0,\n",
       "    'avg_logprob': -0.9082957108815511,\n",
       "    'compression_ratio': 0.5,\n",
       "    'no_speech_prob': 0.27759456634521484}],\n",
       "  'language': 'en'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs = generate_transcripts(r\"N:\\Open_LLM\\spch_dirz\\audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing speech diarization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\novil\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\\pytorch_model.bin`\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cpu. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech diarization completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'playlist.wav': [{'start': 19.28534375,\n",
       "   'end': 20.06159375,\n",
       "   'speaker': 'SPEAKER_00'},\n",
       "  {'start': 66.38346875, 'end': 67.17659375000001, 'speaker': 'SPEAKER_00'},\n",
       "  {'start': 113.48159375, 'end': 114.25784375, 'speaker': 'SPEAKER_00'},\n",
       "  {'start': 160.57971875, 'end': 161.37284375000002, 'speaker': 'SPEAKER_00'},\n",
       "  {'start': 177.69096875000002, 'end': 178.85534375, 'speaker': 'SPEAKER_01'},\n",
       "  {'start': 207.69471875000002,\n",
       "   'end': 208.47096875000003,\n",
       "   'speaker': 'SPEAKER_00'},\n",
       "  {'start': 224.80596875, 'end': 225.95346875, 'speaker': 'SPEAKER_01'}],\n",
       " 'test_meeting.wav': [{'start': 19.28534375,\n",
       "   'end': 20.06159375,\n",
       "   'speaker': 'SPEAKER_00'},\n",
       "  {'start': 66.38346875, 'end': 67.17659375000001, 'speaker': 'SPEAKER_00'},\n",
       "  {'start': 113.48159375, 'end': 114.25784375, 'speaker': 'SPEAKER_00'},\n",
       "  {'start': 160.57971875, 'end': 161.37284375000002, 'speaker': 'SPEAKER_00'},\n",
       "  {'start': 177.69096875000002, 'end': 178.85534375, 'speaker': 'SPEAKER_01'},\n",
       "  {'start': 207.69471875000002,\n",
       "   'end': 208.47096875000003,\n",
       "   'speaker': 'SPEAKER_00'},\n",
       "  {'start': 224.80596875, 'end': 225.95346875, 'speaker': 'SPEAKER_01'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_diarization(r\"N:\\Open_LLM\\spch_dirz\\audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SPEAKER_02',\n",
       "  0.0,\n",
       "  26.0,\n",
       "  \" We don't have the capability of a scanner.  So you can't scan and put the men in it.  If you send it to us a day before,  I don't even know if there's a scanner in the building.  I think there may be one downstairs in the clerk's office.  And so putting stuff electronically up,  the amendments is something  the Mexico has fallen behind with technology driven access.\"],\n",
       " ['SPEAKER_01',\n",
       "  26.0,\n",
       "  65.64,\n",
       "  \" Mr. Chair, I think it's actually a rule that we've passed  a law may be even represented in the Queen saying  that all amendments would actually have to be posted online.  This may be the only,  maybe I'll do respect that we don't post these amendments,  these documents, and I just think we should.  I think it's public information,  and I just think nothing can be more important.  A $10 billion budget from a policy standpoint  and everything contained in it.  So I think, Shana, I mean, with all the other committees  and legislature amendments, because of that rule,  what is the common practice of things being put online  and uptime, how timely are those, really?\"],\n",
       " ['SPEAKER_00',\n",
       "  68.6,\n",
       "  112.64,\n",
       "  \" Mr. Chair, Senator, your correct joint rule  was passed a year or so ago.  Last year was the first year of implementation.  The posting of the amendments received by committees  or when they're put on in the committee  is the role of the committee secretary and committee staff,  but from the council service,  we do provide committee secretaries with PDFs  of any proposed amendment or substitute  that's going to be before a committee.  And the only exception is that our duty of confidentiality  does flow directly to you as legislators,  and so if you were to tell us not to distribute that amendment,  we do follow your direction on that,  but that is the common practice  to deliver the PDFs to the committee secretary.\"],\n",
       " ['SPEAKER_01',\n",
       "  113.68,\n",
       "  116.64,\n",
       "  \" And then they can put online while they're being discussed\"],\n",
       " ['SPEAKER_00',\n",
       "  117.32000000000001,\n",
       "  121.04,\n",
       "  ' Mr. Chair in the Senate that has been the practice last year.'],\n",
       " ['SPEAKER_02',\n",
       "  121.04,\n",
       "  172.56,\n",
       "  \" Okay, and we've done that as soon as they're adopted.  We can put the amendment on because we don't know  if it's going to pass or not.  So the amendment in the PDF is not put online,  the thing just told me until the amendment passes  because we don't know what it does.  I mean, we have copies of the amendments,  the sponsor could give them to whoever they wanted  if they want to share the amendment.  If you don't want to share the amendment,  that's a legislature's prerogative.  But they're not put up there for discussion purposes  because the bill hasn't been amended.  And so until they're amended, the amendment's on there.  And then if you want to amend the bill,  if he wants to draft an amendment,  the amendment bill entirely,  we'd have to get the amendment drafted in the bill  and then bring the bill back down  and then know where the amendments are,  which could be a one or two day process  to paying the how big the bill is.\"],\n",
       " ['SPEAKER_01',\n",
       "  174.92000000000002,\n",
       "  198.12,\n",
       "  \" Anyone who's chair to the extent possible,  I just personally like putting it out there.  I had a time including putting it online,  which probably can be done just as well as after the fact.  And just like a bill we vote on,  that hasn't been adopted, but anyway,  I'll just, that's how I feel about it, you know,  Mr. Chair and then same usual deal.  So appreciate the discussion.  Thank you.\"],\n",
       " ['SPEAKER_02',\n",
       "  198.12,\n",
       "  207.48000000000002,\n",
       "  \" We don't have text messaging to the lobbyists  can text us if they like the amendments or not.  I'm sure.  We don't have to put some play in the amendment process anyway.  Senator Gonzalez.  Thank you.\"],\n",
       " ['SPEAKER_00',\n",
       "  207.48000000000002,\n",
       "  213.76000000000002,\n",
       "  ' And we also have to take the advice from council,  because sometimes it turns into a substitute.'],\n",
       " ['SPEAKER_02',\n",
       "  219.20000000000002,\n",
       "  239.48000000000002,\n",
       "  \" Any other questions?  We're going to be as transparent as we can, but, you know,  we get moving in certain times and it's just,  we can't manage every little detail.  So you're here to talk to us about bills and.\"],\n",
       " ['SPEAKER_00',\n",
       "  239.48000000000002,\n",
       "  241.04000000000002,\n",
       "  ' Thank you, Mr. Chair.  Yes.'],\n",
       " ['SPEAKER_02', 241.04000000000002, 242.28, \" I'm seeing the old song.\"],\n",
       " ['SPEAKER_00',\n",
       "  244.88000000000002,\n",
       "  247.88000000000002,\n",
       "  ' So I was requested.  Mr. Chair,'],\n",
       " ['SPEAKER_02',\n",
       "  247.88000000000002,\n",
       "  253.76000000000002,\n",
       "  \" now Senator Gonzalez, we're going to need to go into executive now.  I'm going to make a motion.\"],\n",
       " ['SPEAKER_01',\n",
       "  253.76000000000002,\n",
       "  257.92,\n",
       "  ' Mr. Chair, some will, though, we go into executive session.'],\n",
       " ['SPEAKER_02',\n",
       "  257.92,\n",
       "  269.03999999999996,\n",
       "  \" Second, Senator Chendot, any objection to go into executive?  No, we're not talking about personnel.  We're going to talk about bills.\"]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load your transcript\n",
    "\n",
    "with open(r\"N:\\Open_LLM\\spch_dirz\\senet_fin_transcript.json\", 'r') as fp:\n",
    "    transcript = json.load(fp)\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert transcript to SRT format\n",
    "srt_content = \"\"\n",
    "for i, entry in enumerate(transcript):\n",
    "    start_time = entry[1]\n",
    "    end_time = entry[2]\n",
    "    text = entry[3]\n",
    "    srt_content += f\"{i+1}\\n\"\n",
    "    srt_content += f\"{start_time:.3f} --> {end_time:.3f}\\n\"\n",
    "    srt_content += f\"{text}\\n\\n\"\n",
    "\n",
    "# Save SRT content to file\n",
    "with open(r\"N:\\Open_LLM\\spch_dirz\\senet_fin_transcript.srt\", \"w\") as f:\n",
    "    f.write(srt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def convert_to_srt(transcript, output_srt_path):\n",
    "    with open(output_srt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, entry in enumerate(transcript, start=1):\n",
    "            speaker, start_time, end_time, text = entry\n",
    "            # Convert seconds to SRT timestamp format\n",
    "            start_hms = f\"{int(start_time//3600):02}:{int((start_time%3600)//60):02}:{start_time%60:06.3f}\"\n",
    "            end_hms = f\"{int(end_time//3600):02}:{int((end_time%3600)//60):02}:{end_time%60:06.3f}\"\n",
    "            # Replace decimal points with commas\n",
    "            start_hms = start_hms.replace(\".\", \",\")\n",
    "            end_hms = end_hms.replace(\".\", \",\")\n",
    "            # Write subtitle entry\n",
    "            f.write(f\"{idx}\\n{start_hms} --> {end_hms}\\n{speaker}: {text.strip()}\\n\\n\")\n",
    "\n",
    "# Your transcript data\n",
    "with open(r\"N:\\Open_LLM\\spch_dirz\\senet_fin_transcript.json\", 'r') as fp:\n",
    "    transcript = json.load(fp)\n",
    "\n",
    "\n",
    "\n",
    "# Generate SRT file\n",
    "convert_to_srt(transcript, r\"N:\\Open_LLM\\spch_dirz\\videos\\senet_fin_transcript2.srt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Play video with subtitles using VLC\n",
    "video_path = \"your_video.mp4\"\n",
    "subprocess.run([\n",
    "    \"vlc\",\n",
    "    \"--sub-file\", \"subtitles.srt\",\n",
    "    video_path\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_srt(srt_path):\n",
    "    with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    index = 1\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        # Check sequence number\n",
    "        if lines[i].strip() != str(index):\n",
    "            print(f\"Error: Invalid sequence number at line {i+1}. Expected {index}, got {lines[i].strip()}\")\n",
    "            return False\n",
    "        i += 1\n",
    "\n",
    "        # Check timestamps\n",
    "        if \"-->\" not in lines[i]:\n",
    "            print(f\"Error: Missing timestamp at line {i+1}.\")\n",
    "            return False\n",
    "        try:\n",
    "            start, end = lines[i].strip().split(\" --> \")\n",
    "            # Validate format (HH:MM:SS,mmm)\n",
    "            assert len(start) == 12 and start.count(\":\") == 2 and start.count(\",\") == 1\n",
    "            assert len(end) == 12 and end.count(\":\") == 2 and end.count(\",\") == 1\n",
    "        except:\n",
    "            print(f\"Error: Invalid timestamp format at line {i+1}: {lines[i].strip()}\")\n",
    "            return False\n",
    "        i += 1\n",
    "\n",
    "        # Skip subtitle text lines\n",
    "        while i < len(lines) and lines[i].strip() != \"\":\n",
    "            i += 1\n",
    "        i += 1  # Skip empty line\n",
    "        index += 1\n",
    "\n",
    "    print(\"SRT file is valid!\")\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRT file is valid!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "validate_srt(r\"N:\\Open_LLM\\spch_dirz\\videos\\senet_fin_transcript2.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dafl_budget",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
